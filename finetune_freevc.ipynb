{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning FreeVC\n",
    "\n",
    "Hi!\n",
    "\n",
    "This notebook takes you through the steps to **fine-tune** the **Voice Conversion** model **FreeVC**. It is meant to be beginner-friendly, sparing you (and myself, the author of this notebook) most of the details of FreeVC's incredibly complicated Architecture. To those looking for a deeper dive into some of the concepts, models and techniques on which FreeVC is built, there will be some links to further reading.\n",
    "\n",
    "> FreeVC:\n",
    ">- [Paper](https://arxiv.org/abs/2210.15418)\n",
    ">- [Demo](https://olawod.github.io/FreeVC-demo/)\n",
    ">- [Code](https://github.com/OlaWod/FreeVC)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove before shipping\n",
    "# ! python initialize.py --leave_chunks\n",
    "# DO_NOT_CHUNK = True\n",
    "# DO_NOT_CHUNK = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- testing\n",
    "    - what & how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "### What is Voice Conversion?\n",
    "- TODO: go through the basics\n",
    "\n",
    "### FreeVC: Architecture\n",
    "\n",
    "#### VITS\n",
    "A significant part of FreeVC's architecture is based on [**VITS**](https://github.com/jaywalnut310/vits), an **end-to-end TTS** (text-to-speech) model. \n",
    "- TODO: further reading\n",
    "\n",
    "\n",
    "#### WAVLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "\n",
    "\n",
    "### Installation/Prerequisites\n",
    "- WavLM\n",
    "- HiFiGAN\n",
    "- venv:\n",
    "    - `pip install -r requirements.txt`\n",
    "    - TODO: ensure the following packages are included in the requirements\n",
    "        - protobuf<=3.20.3\n",
    "        - six==1.16.0\n",
    "        - matplotlib\n",
    "        - numpy<=1.22.4\n",
    "- ffmpeg: to enable exporting as flac\n",
    "    - `sudo apt update && sudo apt upgrade` `sudo apt install ffmpeg`\n",
    "    - `ffmpeg -version` to check the installation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Preparation\n",
    "\n",
    "To finetune the pre-trained model, we of course need some training data to adapt the model to the target speaker. With _some_ training data, I mean a whole lot of it.\n",
    "\n",
    "We want to make sure we make the most of our data. Therefore, we'll do some simple preprocessing on it.\n",
    "\n",
    "#### Chop it up\n",
    "\n",
    "The **base model** (i.e. FreeVC's pretrained model that we're finetuning) is trained on the [VCTK corpus](https://datashare.ed.ac.uk/handle/10283/3443). The audio in this corpus is stored in multiple smaller files (3.4 seconds on average) than one large file.\n",
    "\n",
    "If your finetuning-data is already in similarly sized chunks, you can **skip this step**. Otherwise, run the following cells on your file(s): This will automatically detect silent passages - for example between sentences, and thus split your audio into adequately sized chunks.\n",
    "\n",
    "You can modify the following parameters to control the chunking:\n",
    "- `MIN_SILENCE_LEN` (miliseconds): Defines the minimal length of silence necessary to split the audio at that point\n",
    "- `SILENCE_THRESHOLD` (dBFS): Defines what counts as silent and what does not; anything louder than the set threshold will count as not silent. \n",
    "- `MIN_CHUNK_LEN` (seconds): Any chunk shorter than this value will be discarded and NOT saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified code, originally from:\n",
    "#   https://www.codespeedy.com/split-audio-files-using-silence-detection-in-python/\n",
    "#   retrieved on 2024-08-23\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "def chunk_audio(filelist: list[str],silence_len=800,silence_thr=-40, chunklen=0):\n",
    "    count = 0\n",
    "    length = 0.\n",
    "    for file in filelist:\n",
    "        sound = AudioSegment.from_wav(file)\n",
    "        # print(sound.duration_seconds)\n",
    "        # spliting audio files\n",
    "        audio_chunks = split_on_silence(sound, min_silence_len=silence_len, silence_thresh=silence_thr)\n",
    "        #loop is used to iterate over the output list\n",
    "        for i, chunk in enumerate(audio_chunks):\n",
    "            # save them as a FLAC file\n",
    "            output_file = \"./chunks/chunk{0}.flac\".format(i)\n",
    "            if not os.path.exists(\"./chunks\"):\n",
    "                os.makedirs(\"./chunks/\")\n",
    "            if chunk.duration_seconds >= chunklen:\n",
    "                print(\"Exporting file\", output_file)\n",
    "                chunk.export(output_file, format=\"flac\")\n",
    "                length += chunk.duration_seconds\n",
    "                count += 1\n",
    "            else:\n",
    "                print(\"Skipping Chunk {0}: Too short (< {1} seconds)\".format(i,chunklen))\n",
    "    print(\"\\nAverage length of saved chunks: {0} Seconds\".format(round(length/count,2)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Chunk 0: Too short (< 1.5 seconds)\n",
      "Skipping Chunk 1: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk2.flac\n",
      "Exporting file ./chunks/chunk3.flac\n",
      "Exporting file ./chunks/chunk4.flac\n",
      "Exporting file ./chunks/chunk5.flac\n",
      "Exporting file ./chunks/chunk6.flac\n",
      "Exporting file ./chunks/chunk7.flac\n",
      "Exporting file ./chunks/chunk8.flac\n",
      "Exporting file ./chunks/chunk9.flac\n",
      "Skipping Chunk 10: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk11.flac\n",
      "Exporting file ./chunks/chunk12.flac\n",
      "Exporting file ./chunks/chunk13.flac\n",
      "Exporting file ./chunks/chunk14.flac\n",
      "Exporting file ./chunks/chunk15.flac\n",
      "Exporting file ./chunks/chunk16.flac\n",
      "Exporting file ./chunks/chunk17.flac\n",
      "Exporting file ./chunks/chunk18.flac\n",
      "Skipping Chunk 19: Too short (< 1.5 seconds)\n",
      "Skipping Chunk 20: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk21.flac\n",
      "Skipping Chunk 22: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk23.flac\n",
      "Exporting file ./chunks/chunk24.flac\n",
      "Skipping Chunk 25: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk26.flac\n",
      "Skipping Chunk 27: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk28.flac\n",
      "Skipping Chunk 29: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk30.flac\n",
      "Exporting file ./chunks/chunk31.flac\n",
      "Skipping Chunk 32: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk33.flac\n",
      "Exporting file ./chunks/chunk34.flac\n",
      "Exporting file ./chunks/chunk35.flac\n",
      "Skipping Chunk 36: Too short (< 1.5 seconds)\n",
      "Skipping Chunk 37: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk38.flac\n",
      "Exporting file ./chunks/chunk39.flac\n",
      "Exporting file ./chunks/chunk40.flac\n",
      "Exporting file ./chunks/chunk41.flac\n",
      "Exporting file ./chunks/chunk42.flac\n",
      "Exporting file ./chunks/chunk43.flac\n",
      "Exporting file ./chunks/chunk44.flac\n",
      "Exporting file ./chunks/chunk45.flac\n",
      "Exporting file ./chunks/chunk46.flac\n",
      "Exporting file ./chunks/chunk47.flac\n",
      "Exporting file ./chunks/chunk48.flac\n",
      "Skipping Chunk 49: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk50.flac\n",
      "Exporting file ./chunks/chunk51.flac\n",
      "Exporting file ./chunks/chunk52.flac\n",
      "Exporting file ./chunks/chunk53.flac\n",
      "Exporting file ./chunks/chunk54.flac\n",
      "Exporting file ./chunks/chunk55.flac\n",
      "Exporting file ./chunks/chunk56.flac\n",
      "Skipping Chunk 57: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk58.flac\n",
      "Exporting file ./chunks/chunk59.flac\n",
      "Exporting file ./chunks/chunk60.flac\n",
      "Exporting file ./chunks/chunk61.flac\n",
      "Skipping Chunk 62: Too short (< 1.5 seconds)\n",
      "Skipping Chunk 63: Too short (< 1.5 seconds)\n",
      "Exporting file ./chunks/chunk64.flac\n",
      "Exporting file ./chunks/chunk65.flac\n",
      "Exporting file ./chunks/chunk66.flac\n",
      "Exporting file ./chunks/chunk67.flac\n",
      "Skipping Chunk 68: Too short (< 1.5 seconds)\n",
      "\n",
      "Average length of saved chunks: 4.05 Seconds\n"
     ]
    }
   ],
   "source": [
    "# VARIABLES\n",
    "MIN_SILENCE_LEN = 800\n",
    "SILENCE_THRESHOLD = -40\n",
    "MIN_CHUNK_LEN = 1.5\n",
    "\n",
    "# USER TODO: list of files to chunk\n",
    "filelist = [\"./LN_AUDIOFILES/brn1/bernie_filibuster_pt1_5min.wav\"]\n",
    "\n",
    "# TODO remove before shipping\n",
    "if not DO_NOT_CHUNK:\n",
    "    chunk_audio(filelist, silence_len=MIN_SILENCE_LEN, silence_thr=SILENCE_THRESHOLD, chunklen=MIN_CHUNK_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "At this point, we have some audio data in appropriately sized chunks. We now need to run some very particular preprocessing steps on it, so that the model receives it in the right format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage Format\n",
    "\n",
    "FreeVC expects our fine-tuning data to be in the same format as its [original training data](https://datashare.ed.ac.uk/handle/10283/3443). Therefore, we need to rename some files and move them to the right places before we run any preprocessing.\n",
    "\n",
    "You'll need to assign some **4-character** ID to your speaker - pick one that makes sense to you. If it's longer or shorter than 4 characters, this won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pick your Speaker ID\n",
    "SPEAKER_ID = \"brn1\"\n",
    "assert len(SPEAKER_ID) == 4\n",
    "\n",
    "# DIRECTORY NAMES\n",
    "CHUNKS = \"./chunks/\"\n",
    "FLACS = \"./dataset/flac/\"\n",
    "DATA_PATH = f'{FLACS}{SPEAKER_ID}/'\n",
    "DATA16K = \"dataset/finetuning-16k\"\n",
    "DATA22K = \"dataset/finetuning-22k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will rename your audio and move it into a directory with the right structure.\n",
    "\n",
    "`<some_dir>/<sp_id>/<sp_id-filename>_mic2.flac`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved and renamed your training files.\n",
      "Great Success!! Very Nice!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "for i,file in enumerate(os.listdir(CHUNKS)):\n",
    "    # print(file)\n",
    "    # rename & move files to the specific format necessary\n",
    "    new_filename = f'{SPEAKER_ID}-{i}_mic2.flac'\n",
    "    a =os.path.join(CHUNKS,file)\n",
    "    shutil.copy(a, os.path.join(DATA_PATH,new_filename))\n",
    "print(\"Moved and renamed your training files.\\nGreat Success!! Very Nice!\")\n",
    "# os.listdir(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampling\n",
    "\n",
    "Downsamples the audio to 16kHz.\n",
    "- `--sr1` sampling rate`\n",
    "- `--sr2` sampling rate`\n",
    "- `--in_dir` path to source dir`\n",
    "- `--out_dir1` path to target dir`\n",
    "- `--out_dir2` path to target dir`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python downsample.py --in_dir $FLACS --out_dir1 $DATA16K --out_dir2 $DATA22K\n",
    "! ln -s $DATA16K DUMMY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Splitting\n",
    "\n",
    "Next, our fine-tuning data will need to be split into a training, test and validation set.\n",
    "\n",
    "The original splitting-script of FreeVC uses 2 chunks from each speaker for validation, 10 chunks for testing and the rest for training. With an average of around 400 chunks per speaker, this is an average test-split of 2.5%, and validation-split of 0.5%. To me, this seems like an overly small test and validation portion.\n",
    "\n",
    "Therefore the preprocessing script was modified:\n",
    "Before, the test and validation portions were constant, at 10 and 2 samples respectively. I changed them to a relative 5% and 1% portion for the test and validation sets.\n",
    "\n",
    "_(As to whether this improves or worsens performance, I have no empirical evidence for either and I do not intend to gather it.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 5178.15it/s]\n",
      "Writing ./filelists/finetune-train.txt\n",
      "100%|███████████████████████████████████████| 48/48 [00:00<00:00, 182196.01it/s]\n",
      "Writing ./filelists/finetune-val.txt\n",
      "100%|██████████████████████████████████████████| 1/1 [00:00<00:00, 14873.42it/s]\n",
      "Writing ./filelists/finetune-test.txt\n",
      "100%|██████████████████████████████████████████| 3/3 [00:00<00:00, 35444.82it/s]\n"
     ]
    }
   ],
   "source": [
    "val_file=\"./filelists/finetune-val.txt\"\n",
    "test_file=\"./filelists/finetune-test.txt\"\n",
    "train_file=\"./filelists/finetune-train.txt\"\n",
    "sr_wavs = f\"./dataset/sr/wav\"\n",
    "# ! python preprocess_flist.py --train_list $train_file --test_list $test_file --val_list $val_file --source_dir $sr_wavs\n",
    "! python preprocess_flist.py --train_list $train_file --test_list $test_file --val_list $val_file --source_dir $DATA16K\n",
    "! rm DUMMY\n",
    "! ln -s $DATA16K DUMMY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$train_file\n"
     ]
    }
   ],
   "source": [
    "# %%bash -s \"$train_file\" \"$test_file\" \"$val_file\" \"$DATA16K\"\n",
    "# echo $1\n",
    "# python preprocess_flist.py --train_list $1 --test_list $2 --val_list $3 --source_dir $4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speaker Encoder (pretrained)\n",
    "\n",
    "Something something encode speaker information using a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root=\"./dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$DATA16K\n",
      "this is $data_root\n"
     ]
    }
   ],
   "source": [
    "! CUDA_VISIBLE_DEVICES=0 python preprocess_spk.py --in_dir $DATA16K --out_dir_root $data_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation\n",
    "\n",
    "To make the most of our data...    ...Spectrogram Resize (SR)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIFIGAN_CFG = \"hifigan/config.json\"\n",
    "WAV_DIR = \"dataset/sr/wav\"\n",
    "SSL_DIR = \"dataset/sr/wavlm\"\n",
    "! CUDA_VISIBLE_DEVICES=0 python preprocess_sr.py --in_dir $DATA22K --wav_dir $WAV_DIR --ssl_dir $SSL_DIR --config $HIFIGAN_CFG --min 68 --max 92 --sr 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning\n",
    "\n",
    "The hyperparameters of training are set in a JSON file, located in the `/configs/` directory. For finetuning, we'll use the file `freevc-finetune.json`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freevc_finetune\n",
      "INFO:freevc-finetune:{'train': {'log_interval': 10, 'eval_interval': 10, 'seed': 1234, 'epochs': 2, 'learning_rate': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 1, 'fp16_run': False, 'lr_decay': 0.999875, 'segment_size': 8960, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0, 'use_sr': True, 'max_speclen': 128, 'port': '8001'}, 'data': {'training_files': 'filelists/finetune-train.txt', 'validation_files': 'filelists/finetune-val.txt', 'max_wav_value': 32768.0, 'sampling_rate': 16000, 'filter_length': 1280, 'hop_length': 320, 'win_length': 1280, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': None}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [10, 8, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'n_layers_q': 3, 'use_spectral_norm': False, 'gin_channels': 256, 'ssl_dim': 1024, 'use_spk': True}, 'model_dir': './logs/freevc-finetune', 'generator': './checkpoints/freevc.pth', 'discriminator': './checkpoints/D-freevc.pth', 'force_new': True}\n",
      "INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "train_loader:  48\n",
      "INFO:freevc-finetune:Loaded checkpoint './checkpoints/freevc.pth' (iteration 1372)\n",
      "INFO:freevc-finetune:Loaded checkpoint './checkpoints/D-freevc.pth' (iteration 1372)\n",
      "filename:  DUMMY/brn1/brn1-8.wav\n",
      "filename:  DUMMY/brn1/brn1-16.wav\n",
      "filename:  DUMMY/brn1/brn1-32.wav\n",
      "filename:  DUMMY/brn1/brn1-14.wav\n",
      "filename:  DUMMY/brn1/brn1-28.wav\n",
      "filename:  DUMMY/brn1/brn1-27.wav\n",
      "filename:  DUMMY/brn1/brn1-5.wav\n",
      "filename:  DUMMY/brn1/brn1-3.wav\n",
      "filename:  DUMMY/brn1/brn1-51.wav\n",
      "filename:  DUMMY/brn1/brn1-45.wav\n",
      "filename:  DUMMY/brn1/brn1-36.wav\n",
      "filename:  DUMMY/brn1/brn1-41.wav\n",
      "filename:  DUMMY/brn1/brn1-44.wav\n",
      "filename:  DUMMY/brn1/brn1-19.wav\n",
      "filename:  DUMMY/brn1/brn1-17.wav\n",
      "filename:  DUMMY/brn1/brn1-21.wav\n",
      "filename:  DUMMY/brn1/brn1-42.wav\n",
      "INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "INFO:freevc-finetune:Train Epoch: 1 [0%]\n",
      "INFO:freevc-finetune:[2.010392904281616, 6.994058609008789, 14.77212905883789, 26.200119018554688, 60.47795867919922, 0, 0.00016845718778664938]\n",
      "DEBUG:matplotlib:matplotlib data path: /home/notmyyka/UZH/pp_vc/FreeVC/.venv-freevc/lib/python3.9/site-packages/matplotlib/mpl-data\n",
      "DEBUG:matplotlib:CONFIGDIR=/home/notmyyka/.config/matplotlib\n",
      "DEBUG:matplotlib:interactive is False\n",
      "DEBUG:matplotlib:platform is linux\n",
      "filename:  DUMMY/brn1/brn1-9.wav\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 1 to ./logs/freevc-finetune/G_0.pth\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 1 to ./logs/freevc-finetune/D_0.pth\n",
      "filename:  DUMMY/brn1/brn1-10.wav\n",
      "INFO:root:Reducer buckets have been rebuilt in this iteration.\n",
      "filename:  DUMMY/brn1/brn1-23.wav\n",
      "filename:  DUMMY/brn1/brn1-20.wav\n",
      "filename:  DUMMY/brn1/brn1-24.wav\n",
      "filename:  DUMMY/brn1/brn1-15.wav\n",
      "filename:  DUMMY/brn1/brn1-38.wav\n",
      "filename:  DUMMY/brn1/brn1-48.wav\n",
      "filename:  DUMMY/brn1/brn1-25.wav\n",
      "filename:  DUMMY/brn1/brn1-50.wav\n",
      "filename:  DUMMY/brn1/brn1-46.wav\n",
      "INFO:freevc-finetune:Train Epoch: 1 [21%]\n",
      "INFO:freevc-finetune:[4.3742852210998535, 4.717919826507568, 13.515385627746582, 32.10834884643555, 6.6031928062438965, 10, 0.00016845718778664938]\n",
      "filename:  DUMMY/brn1/brn1-9.wav\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 1 to ./logs/freevc-finetune/G_10.pth\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 1 to ./logs/freevc-finetune/D_10.pth\n",
      "filename:  DUMMY/brn1/brn1-29.wav\n",
      "filename:  DUMMY/brn1/brn1-2.wav\n",
      "filename:  DUMMY/brn1/brn1-49.wav\n",
      "filename:  DUMMY/brn1/brn1-30.wav\n",
      "filename:  DUMMY/brn1/brn1-6.wav\n",
      "filename:  DUMMY/brn1/brn1-31.wav\n",
      "filename:  DUMMY/brn1/brn1-43.wav\n",
      "filename:  DUMMY/brn1/brn1-13.wav\n",
      "filename:  DUMMY/brn1/brn1-0.wav\n",
      "filename:  DUMMY/brn1/brn1-22.wav\n",
      "INFO:freevc-finetune:Train Epoch: 1 [42%]\n",
      "INFO:freevc-finetune:[2.787867546081543, 3.013143539428711, 10.779343605041504, 26.900354385375977, 6.112410545349121, 20, 0.00016845718778664938]\n",
      "filename:  DUMMY/brn1/brn1-9.wav\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 1 to ./logs/freevc-finetune/G_20.pth\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 1 to ./logs/freevc-finetune/D_20.pth\n",
      "filename:  DUMMY/brn1/brn1-26.wav\n",
      "filename:  DUMMY/brn1/brn1-33.wav\n",
      "filename:  DUMMY/brn1/brn1-37.wav\n",
      "filename:  DUMMY/brn1/brn1-35.wav\n",
      "filename:  DUMMY/brn1/brn1-11.wav\n",
      "filename:  DUMMY/brn1/brn1-12.wav\n",
      "filename:  DUMMY/brn1/brn1-47.wav\n",
      "filename:  DUMMY/brn1/brn1-40.wav\n",
      "filename:  DUMMY/brn1/brn1-4.wav\n",
      "filename:  DUMMY/brn1/brn1-34.wav\n",
      "INFO:freevc-finetune:Train Epoch: 1 [62%]\n",
      "INFO:freevc-finetune:[2.717712640762329, 3.2056026458740234, 9.663077354431152, 29.52743911743164, 5.3559956550598145, 30, 0.00016845718778664938]\n",
      "filename:  DUMMY/brn1/brn1-9.wav\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 1 to ./logs/freevc-finetune/G_30.pth\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 1 to ./logs/freevc-finetune/D_30.pth\n",
      "filename:  DUMMY/brn1/brn1-1.wav\n",
      "INFO:freevc-finetune:Train Epoch: 1 [83%]\n",
      "INFO:freevc-finetune:[2.5944182872772217, 3.653904438018799, 9.949706077575684, 25.58915901184082, 3.5754499435424805, 40, 0.00016845718778664938]\n",
      "filename:  DUMMY/brn1/brn1-9.wav\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 1 to ./logs/freevc-finetune/G_40.pth\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 1 to ./logs/freevc-finetune/D_40.pth\n",
      "INFO:freevc-finetune:====> Epoch: 1\n",
      "filename:  DUMMY/brn1/brn1-6.wav\n",
      "filename:  DUMMY/brn1/brn1-41.wav\n",
      "filename:  DUMMY/brn1/brn1-51.wav\n",
      "filename:  DUMMY/brn1/brn1-4.wav\n",
      "filename:  DUMMY/brn1/brn1-1.wav\n",
      "filename:  DUMMY/brn1/brn1-21.wav\n",
      "filename:  DUMMY/brn1/brn1-15.wav\n",
      "filename:  DUMMY/brn1/brn1-24.wav\n",
      "filename:  DUMMY/brn1/brn1-25.wav\n",
      "filename:  DUMMY/brn1/brn1-0.wav\n",
      "filename:  DUMMY/brn1/brn1-19.wav\n",
      "filename:  DUMMY/brn1/brn1-8.wav\n",
      "filename:  DUMMY/brn1/brn1-23.wav\n",
      "filename:  DUMMY/brn1/brn1-10.wav\n",
      "filename:  DUMMY/brn1/brn1-14.wav\n",
      "filename:  DUMMY/brn1/brn1-47.wav\n",
      "filename:  DUMMY/brn1/brn1-40.wav\n",
      "filename:  DUMMY/brn1/brn1-17.wav\n",
      "filename:  DUMMY/brn1/brn1-30.wav\n",
      "INFO:freevc-finetune:Train Epoch: 2 [4%]\n",
      "INFO:freevc-finetune:[2.669412851333618, 2.9398128986358643, 8.301678657531738, 24.379858016967773, 4.999719142913818, 50, 0.00016843613063817603]\n",
      "filename:  DUMMY/brn1/brn1-9.wav\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 2 to ./logs/freevc-finetune/G_50.pth\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 2 to ./logs/freevc-finetune/D_50.pth\n",
      "filename:  DUMMY/brn1/brn1-45.wav\n",
      "filename:  DUMMY/brn1/brn1-5.wav\n",
      "filename:  DUMMY/brn1/brn1-22.wav\n",
      "filename:  DUMMY/brn1/brn1-29.wav\n",
      "filename:  DUMMY/brn1/brn1-42.wav\n",
      "filename:  DUMMY/brn1/brn1-31.wav\n",
      "filename:  DUMMY/brn1/brn1-3.wav\n",
      "filename:  DUMMY/brn1/brn1-32.wav\n",
      "filename:  DUMMY/brn1/brn1-49.wav\n",
      "filename:  DUMMY/brn1/brn1-20.wav\n",
      "INFO:freevc-finetune:Train Epoch: 2 [25%]\n",
      "INFO:freevc-finetune:[2.6520676612854004, 2.9294228553771973, 9.034720420837402, 24.587329864501953, 3.212935447692871, 60, 0.00016843613063817603]\n",
      "filename:  DUMMY/brn1/brn1-9.wav\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 2 to ./logs/freevc-finetune/G_60.pth\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 2 to ./logs/freevc-finetune/D_60.pth\n",
      "filename:  DUMMY/brn1/brn1-27.wav\n",
      "filename:  DUMMY/brn1/brn1-38.wav\n",
      "filename:  DUMMY/brn1/brn1-36.wav\n",
      "filename:  DUMMY/brn1/brn1-44.wav\n",
      "filename:  DUMMY/brn1/brn1-28.wav\n",
      "filename:  DUMMY/brn1/brn1-33.wav\n",
      "filename:  DUMMY/brn1/brn1-46.wav\n",
      "filename:  DUMMY/brn1/brn1-2.wav\n",
      "filename:  DUMMY/brn1/brn1-35.wav\n",
      "filename:  DUMMY/brn1/brn1-37.wav\n",
      "INFO:freevc-finetune:Train Epoch: 2 [46%]\n",
      "INFO:freevc-finetune:[2.1860549449920654, 2.5580296516418457, 5.534112930297852, 26.266923904418945, 2.5229082107543945, 70, 0.00016843613063817603]\n",
      "filename:  DUMMY/brn1/brn1-9.wav\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 2 to ./logs/freevc-finetune/G_70.pth\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 2 to ./logs/freevc-finetune/D_70.pth\n",
      "filename:  DUMMY/brn1/brn1-13.wav\n",
      "filename:  DUMMY/brn1/brn1-26.wav\n",
      "filename:  DUMMY/brn1/brn1-50.wav\n",
      "filename:  DUMMY/brn1/brn1-16.wav\n",
      "filename:  DUMMY/brn1/brn1-34.wav\n",
      "filename:  DUMMY/brn1/brn1-48.wav\n",
      "filename:  DUMMY/brn1/brn1-12.wav\n",
      "filename:  DUMMY/brn1/brn1-43.wav\n",
      "filename:  DUMMY/brn1/brn1-11.wav\n",
      "INFO:freevc-finetune:Train Epoch: 2 [67%]\n",
      "INFO:freevc-finetune:[2.9834413528442383, 2.4088377952575684, 10.471174240112305, 25.31476402282715, 2.9278931617736816, 80, 0.00016843613063817603]\n",
      "filename:  DUMMY/brn1/brn1-9.wav\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 2 to ./logs/freevc-finetune/G_80.pth\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 2 to ./logs/freevc-finetune/D_80.pth\n",
      "INFO:freevc-finetune:Train Epoch: 2 [88%]\n",
      "INFO:freevc-finetune:[2.238560676574707, 2.5140392780303955, 6.960983753204346, 21.335159301757812, 5.208609580993652, 90, 0.00016843613063817603]\n",
      "filename:  DUMMY/brn1/brn1-9.wav\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 2 to ./logs/freevc-finetune/G_90.pth\n",
      "INFO:freevc-finetune:Saving model and optimizer state at iteration 2 to ./logs/freevc-finetune/D_90.pth\n",
      "INFO:freevc-finetune:====> Epoch: 2\n"
     ]
    }
   ],
   "source": [
    "# train freevc: use config 'configs/freevc-finetune.json', use model 'freevc'\n",
    "# ! CUDA_VISIBLE_DEVICES=0 python finetune.py --config configs/freevc-finetune.json --model freevc-finetune\n",
    "MODEL_NAME = f'freevc_finetune-{SPEAKER_ID}'\n",
    "MODEL_NAME = f'freevc_finetune'\n",
    "! echo $MODEL_NAME\n",
    "! CUDA_VISIBLE_DEVICES=0 python finetune.py -c configs/freevc-finetune.json -m freevc-finetune -d ./checkpoints/D-freevc.pth -g ./checkpoints/freevc.pth --force_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loading checkpoint...\n",
      "logs/freevc-finetune/G_40.pth\n",
      "INFO:root:Loaded checkpoint 'logs/freevc-finetune/G_40.pth' (iteration 1)\n",
      "Loading WavLM for content...\n",
      "INFO:wavlm.WavLM:WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}\n",
      "Loading speaker encoder...\n",
      "Loaded the voice encoder model on cuda in 0.08 seconds.\n",
      "Processing text...\n",
      "Synthesizing...\n",
      "2it [00:06,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# ! CUDA_VISIBLE_DEVICES=0 python convert.py --hpfile configs/freevc-finetune.json --ptfile checkpoints/freevc-finetune.pth --txtpath convert.txt --outdir outputs/freevc-finetune\n",
    "# ! CUDA_VISIBLE_DEVICES=0 python convert.py --hpfile configs/freevc.json --ptfile checkpoints/freevc.pth --txtpath convert.txt --outdir outputs/freevc-base\n",
    "! CUDA_VISIBLE_DEVICES=0 python convert.py --hpfile configs/freevc-finetune.json --ptfile logs/freevc-finetune/G_40.pth --txtpath convert.txt --outdir outputs/freevc-finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import IPython\n",
    "ref_1 = \"\"\n",
    "print(\"Ref 1\")\n",
    "IPython.display.display(ipd.Audio(ref_1.numpy(), rate=sr))\n",
    "print(\"Example 1\")\n",
    "IPython.display.display(ipd.Audio(example_1.numpy(), rate=sr))\n",
    "print(\"Example 2\")\n",
    "IPython.display.display(ipd.Audio(example_2.numpy(), rate=sr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE LATER, JUST STATS\n",
    "\n",
    "import os\n",
    "def test_split(total_len):\n",
    "    n_test = max(round(total_len*0.05), 1)\n",
    "    n_val = max(round(total_len*0.01), 1)\n",
    "    n_train = total_len-(n_test+n_val)\n",
    "\n",
    "    assert total_len == n_test+n_val+n_train\n",
    "    print(total_len, \":\\t\",n_train,\", \",n_test,\", \", n_val)\n",
    "    assert total_len>=10, \"message something\"\n",
    "\n",
    "dir = os.path.abspath(\"~/\")\n",
    "os.walk(dir)\n",
    "vctk_path = os.path.abspath(\"../../../../../../mnt/c/Users/mhess/Downloads/VCTK-Corpus-0.92/wav48_silence_trimmed\")\n",
    "dirlist = os.listdir(vctk_path)\n",
    "# TODO: get avg number of chunks/speaker in vctk\n",
    "counter = 0\n",
    "num_chunks = 0\n",
    "for el in dirlist:\n",
    "    combined_path = os.path.join(vctk_path,el)\n",
    "    # print(f'{el}:\\t{os.path.isdir(combined_path)}')\n",
    "    if os.path.isdir(combined_path):\n",
    "        counter += 1\n",
    "        num_chunks += (len(os.listdir(combined_path)))/2\n",
    "\n",
    "print(f'AVG chunks per speaker: {round(num_chunks/counter, 2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-freevc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
